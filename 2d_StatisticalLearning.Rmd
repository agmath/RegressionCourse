---
title: "MAT 300: An Overview of Statistical Learning"
output:
  html_document
---

```{r global-options, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
library(MASS)
library(tidyverse)
library(patchwork)
```

<div id = "boxedtext"> **Objectives**: After today, you should be able to answer...
  
  + What is statistical learning in terms of regression?
  + Why try to build models (estimate $f$)?
  + Why are prediction and interpretation competing objectives?
  + What are noise, reducible error, and irreducible error?
  + What are parametric and non-parametric models?
  + How do I identify regression versus classification problems?
  + What is the difference between supervised and unsupervised learning?
</div>

## What is Statistical Learning?

<div id = "boxedtext"> Consider some phenomenon which is measured by a variable $Y$. If we think that $Y$ is influenced by or related to some set of predictior variables $X = \left(X_1,~X_2,~...,~X_p\right)$, then we are hypothesizing that
$$\displaystyle{Y~=~f\left(X\right) + \varepsilon}$$
That is, $Y$ is explained by the predictors in $X$ along with some random error, $\varepsilon$ (noise).

  + We assume that $\varepsilon~\sim~N\left(0,\sigma\right)$.
    
    + Note that if $\mu_{\varepsilon}\neq 0$, we would just adjust the intercept to observe an improvement in prediction accuracy. This means that assuming $\mu_{\varepsilon} = 0$ is a reasonable thing to do -- the mathematics guarantees it.
    + Note also that we are assuming that $\sigma$ is constant. That is, $\sigma$ does not depend on the values of any predictors or the response.

These assumptions are crucial to constructing appropriate confidence intervals for predictions.
</div>

<div id = "boxedtext"> **Our Regression Models**: The models we fit in regression will be of the form:
$$\mathbb{E}\left[Y\right] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...$$
this is called a *parametric* model. because we are estimating the parameters $\beta_0,~\beta_1,~\beta_2,...$. 

  + The procedure we use to fit models in this course is called *linear regression* because the model is linear in the $\beta$ parameters. 
  + Regression models involving higher-order ($x_i^k$) or mixed ($x_ix_j$) terms are still *linear regression models*.

We may see some examples of *nonparametric* models later in our course. They typically involve fitting lots of pieces of functions together (step functions, splines, etc.). Nonparametric models have little value for interpretation.
</div>

<div id = "boxedtext"> **Some Simple [Single Predictor] Examples**: Consider the following examples:

```{r echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE, results = FALSE}
par(mfrow = c(2,3))
set.seed(11)

library(tidyverse)

x1 <- runif(100, 0, 100)
x2 <- runif(100, 0, 100)
x3 <- runif(100, 0, 100)

y1 <- 100*sin((pi/80)*(x1 - 40)) + rnorm(100, 0, 10)
y2 <- x2 + rnorm(100, 0, 20)
y3 <- -0.05*(x3-75)^2 + 50 + rnorm(100, 0, 20)

dat <- data.frame(x1, y1, x2, y2, x3, y3)

lm1 <- lm(y1 ~ x1)
lm2 <- lm(y2 ~ x2)
lm3 <- lm(y3 ~ x3)
summary(lm1)

pred.lm1 <- predict(lm1, newdata = dat)
pred.lm2 <- predict(lm2, newdata = dat)
pred.lm3 <- predict(lm3, newdata = dat)

pm1 <- lm(y1 ~ poly(x1, 3, raw = TRUE))
pm2 <- lm(y2 ~ poly(x2, 10, raw = TRUE))
pm3 <- lm(y3 ~ poly(x3, 40, raw = TRUE))
pred.pm1 <- predict(pm1, newdata = dat)
pred.pm2 <- predict(pm2, newdata = dat)
pred.pm3 <- predict(pm3, newdata = dat)

p1 <- ggplot(data = dat) + geom_point(mapping = aes(x = x1, y = y1), size = 2) + geom_line(mapping = aes(x = x1, y = pred.lm1), color = "purple", alpha = 0.6, se = FALSE, lwd = 2)

p2 <- ggplot(data = dat) + geom_point(mapping = aes(x = x2, y = y2), size = 2) + geom_line(mapping = aes(x = x2, y = pred.lm2), color = "purple", alpha = 0.6, se = FALSE, lwd = 2)

p3 <- ggplot(data = dat) + geom_point(mapping = aes(x = x3, y = y3), size = 2) + geom_line(mapping = aes(x = x3, y = pred.lm3), color = "purple", alpha = 0.6, se = FALSE, lwd = 2)

p4 <- ggplot(data = dat) + geom_point(mapping = aes(x = x1, y = y1), size = 2) + geom_line(mapping = aes(x = x1, y = pred.pm1), color = "orange", alpha = 0.6, size = 2)

p5 <- ggplot(data = dat) + geom_point(mapping = aes(x = x2, y = y2), size = 2) + geom_line(mapping = aes(x = x2, y = pred.pm2), color = "orange", alpha = 0.6, size = 2)

p6 <- ggplot(data = dat) + geom_point(mapping = aes(x = x3, y = y3), size = 2) + geom_line(mapping = aes(x = x3, y = pred.pm3), color = "orange", alpha = 0.6, size = 2)

(p1 + p2 + p3)/(p4 + p5 + p6)
```
</div>

<div id = "boxedtext"> **Overfitting (an aside)**: More complicated models will always fit the training data more closely, but are likely to overfit. That is, complicated models run a higher risk of trying to fit noise.

```{r echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE, results = FALSE}

par(mfrow = c(2,3))
set.seed(12)

xa <- runif(100, 0, 100)
xb <- runif(100, 0, 100)
xc <- runif(100, 0, 100)

ya <- 100*sin((pi/80)*(xa - 40)) + rnorm(100, 0, 10)
yb <- xb + rnorm(100, 0, 20)
yc <- -0.05*(xc-75)^2 + 50 + rnorm(100, 0, 20)

dat2 <- data.frame(xa, yb, xc, ya, xb, yc)

p1 <- ggplot(data = dat2) + geom_point(mapping = aes(x = xa, y = ya), size = 2) + geom_line(mapping = aes(x = x1, y = pred.lm1), color = "purple", alpha = 0.6, se = FALSE, lwd = 2)

p2 <- ggplot(data = dat2) + geom_point(mapping = aes(x = xb, y = yb), size = 2) + geom_line(mapping = aes(x = x2, y = pred.lm2), color = "purple", alpha = 0.6, se = FALSE, lwd = 2)

p3 <- ggplot(data = dat2) + geom_point(mapping = aes(x = xc, y = yc), size = 2) + geom_line(mapping = aes(x = x3, y = pred.lm3), color = "purple", alpha = 0.6, se = FALSE, lwd = 2)

p4 <- ggplot(data = dat2) + geom_point(mapping = aes(x = xa, y = ya), size = 2) + geom_line(mapping = aes(x = x1, y = pred.pm1), color = "orange", alpha = 0.6, size = 2)

p5 <- ggplot(data = dat2) + geom_point(mapping = aes(x = xb, y = yb), size = 2) + geom_line(mapping = aes(x = x2, y = pred.pm2), color = "orange", alpha = 0.6, size = 2)

p6 <- ggplot(data = dat2) + geom_point(mapping = aes(x = xc, y = yc), size = 2) + geom_line(mapping = aes(x = x3, y = pred.pm3), color = "orange", alpha = 0.6, size = 2)

(p1 + p2 + p3)/(p4 + p5 + p6)
```
</div>

<div id = "boxedtext"> **Training and Test (Validation) Sets**: One way we will try to avoid overfitting is by taking our data and splitting it into a *training set* used for exploratory analyses and model fitting, and a *test set* (or validation set) used to see how the fitted model performs on new, unseen data. The following rule of thumb is a good starting point.

  + Training sets should contain about 75% of observations
  + Test sets should contain the remaining observations

The training and test sets should be the result of a random sampling of your data *units*. This may be a random sample of the rows in your data frame or, if we have repeated measurements of the same individual over time, may result from a random sample of individuals.
</div>

## Errors in Prediction

<div id = "boxedtext"> **Reducible and Irreducible Errors**: The error in approximating the relationship 
$$Y = f\left(X\right) + \varepsilon$$
by 
$$\hat{Y} = \hat{f}\left(X\right)$$
comes in two pieces:

  + **Reducible Error** is the error that could be lessened by
  
    + using a more appropriate statistical learning technique
    + adjusting the proposed model form
    + utilizing additional predictors

  + **Irreducible Error** is error that is attributed to random noise in the relationship that cannot be predicted. The prediction error cannot be reduced below the irreducible error.
  
## Regression Vesus Classification

<div id = "boxedtext"> When the response variable is numerical, we use regression models. When the response variable is categorical, we use classification. Note that regression problems can always be turned into classification problems, but classification problems cannot [in general] be converted to regression problems.
</div>

## Supervised Versus Unsupervised Learning

<div id = "boxedtext"> An application of statistical learning is *supervised* if the dataset contains a response variable that we are trying to predict or explain. Sometimes there is no response variable, and we would like to do something like identify observations which seem to be similar and to group them together (called clustering). If there is no response being predicted, then we have an *unsupervised* scenario. 

  + Regression problems must be supervised.
</div>

## Closing...

<div id = "boxedtext"> **Homework**: Please do the following for homework before our next meeting:

  + Chapter 2, problems 1, 2, and 4
  + Download the `AnalyticsReportShell.rmd` file from BrightSpace and open it in RStudio. Use it to complete `Competition Assignment 1`.
</div>

