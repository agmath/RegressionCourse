---
title: "Statistical Inference in Regression"
author: Dr. Gilbert
format: 
  revealjs:
    smaller: true
date: today
date-format: long
theme: serif
incremental: true
---

```{r global-options, include=FALSE}
library(tidyverse)
library(tidymodels)
library(patchwork)
library(kableExtra)

tidymodels_prefer()

set.seed(567)
num_pts <- 20
x1 <- runif(num_pts, 0, 10)
x2 <- runif(num_pts, 0, 10) 
y1 <- 4*x1 - 1 + rnorm(num_pts, 0, 8)
y2 <- 4*x1 - 1 + rnorm(num_pts, 0, 30)

num_new <- 10
x1_new <- runif(num_new, 0, 10)
x2_new <- runif(num_new, 0, 10)
y1_new <- 4*x1_new - 1 + rnorm(num_new, 0, 8)

data <- tibble(
  x1 = x1,
  x2 = x2,
  y = y1
)

lin_reg_spec <- linear_reg() 
lin_reg_rec <- recipe(y ~ x1 + x2, data = data)
lin_reg_wf <- workflow() %>%
  add_model(lin_reg_spec) %>%
  add_recipe(lin_reg_rec)
lin_reg_fit <- lin_reg_wf %>%
  fit(data)

options(kable_styling_bootstrap_options = c("hover", "striped"))

theme_set(theme_bw(base_size = 20))
```

```{css}
code.sourceCode {
  font-size: 1.3em;
  /* or try font-size: xx-large; */
}
```

## The Highlights

+ Are our models useful?

  + Global tests for model utility
  + Tests on individual model terms

+ Confidence Intervals for Coefficients
+ Intervals for Model Predictions

  + Confidence Intervals
  + Prediction Intervals

## Playing Along

<center>

<br/>

1. Open your notebook from last time

2. As we discuss the different hypothesis test and interval analyses we'll be encountering in the regression context, analyze the corresponding items for your models in that notebook

</center>


## Global Test for Model Utility

. . .

$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k + \varepsilon\\ ~~~~\text{or}~~~~\\ \mathbb{E}\left[y\right] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k$$

. . .

Does our model contain any useful information about predicting/explaining our response variable at all?

. . .

**Hypotheses:**

$$\begin{array}{lcl} H_0 & : & \beta_1 = \beta_2 = \cdots = \beta_k = 0\\
H_a & : & \text{At least one } \beta_i \text{ is non-zero}\end{array}$$

. . . 

```{r}
#| echo: true
#| eval: false

lin_reg_fit %>%
  glance()
```

```{r}
#| echo: false
#| eval: true

lin_reg_fit %>%
  glance() %>%
  kable() %>%
  kable_styling()
```

. . . 

**Result:** Since our $p$ value is less than $0.05$ (it's about $2.3 \times 10^{-6}$), we reject the null hypothesis and accept that at least one of the terms in our model has a non-zero coefficient.

## Global Test for Model Utility in Pictures

$$\begin{array}{lcl} H_0 & : & \beta_1 = \beta_2 = \cdots = \beta_k = 0\\
H_a & : & \text{At least one } \beta_i \text{ is non-zero}\end{array}$$

. . . 

::::{.columns}

:::{.column width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig.height: 10

p1 <- ggplot() + 
  geom_point(aes(x = x1, y = y1),
             size = 3) + 
  geom_hline(yintercept = mean(y1), 
             color = "red", 
             linetype = "dashed", 
             lwd = 2) +
  geom_smooth(aes(x = x1, y = y1),
              method = "lm",
              color = "blue",
              se = FALSE) + 
  labs(title = "Scenario A",
       x = "x1",
       y = "y1")

p2 <- ggplot() + 
  geom_point(aes(x = x1, y = y2),
             size = 3) + 
  geom_hline(yintercept = mean(y2), 
             color = "red", 
             linetype = "dashed", 
             lwd = 2) +
  geom_smooth(aes(x = x1, y = y2),
              method = "lm",
              color = "blue",
              se = FALSE) + 
  labs(title = "Scenario B",
       x = "x1",
       y = "y2")

p1 / p2
```

:::

:::{.column width="50%"}

Are our *sloped* models better (more justifiable) models than the horizontal line?

+ *Sloped* models use predictor information
+ Horizontal models just predict average response, ignoring all observation-specific features

  + They assume that having information about features of an observation gives no advantage in predicting/explaining its response

::: 

::::

## Additional Global Metrics from `glance()`

. . .

```{r}
#| echo: true
#| eval: false

lin_reg_fit %>%
  glance()
```

```{r}
#| echo: false
#| eval: true

lin_reg_fit %>%
  glance() %>%
  kable() %>%
  kable_styling()
```

. . . 

The output from `glance()`ing at our fitted model object gives lots of additional information about overall model fit and quality.

+ The adjusted R-squared value (`adj.r.squared`) measures *the proportion of variation in the response variable which is explained by the terms in our fitted model*.
+ The *adjusted* R-squared value is a better measure than R-squared because *adjusted* R-squared penalizes the inclusion of additional model terms.
+ The `sigma` value is our *residual standard error*, which we'll often call our "*training error*". It is a measure of how far off we should expect our predictions to be, on average (but it is a biased measure).
+ We won't generally consider the additional items in our course.

## Tests on Individual Model Terms

. . . 

$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k + \varepsilon\\ ~~~~\text{or}~~~~\\ \mathbb{E}\left[y\right] = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k$$

. . . 

Okay, so our model has some utility. Do we really need all of those terms?

. . .

**Hypotheses:**

$$\begin{array}{lcl} H_0 & : & \beta_i = 0\\
H_a & : & \beta_i \neq 0\end{array}$$

. . .

```{r}
#| eval: false
#| echo: true

lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy()
```

```{r}
#| eval: true
#| echo: false

lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy() %>%
  kable() %>%
  kable_styling()
```

. . .

**Result:** The `x1` predictor is statistically significant but the `x2` predictor is not. We should drop the `x2` predictor from the model and re-fit it. ($\bigstar$ We'll only ever drop one predictor / model term at a time, using the highest p-value to indicate which.)

## Confidence Intervals (Model Coefficients)

**Reminder:** An approximate 95% confidence interval is between two *standard errors* below and above our *point estimate*.

. . .

$$\left(\text{point estimate}\right) \pm 2\cdot\left(\text{standard error}\right)~~~\textbf{or}~~~\left(\text{point estimate}\right) \pm t^*_{\text{df}}\cdot\left(\text{standard error}\right)$$

. . .

```{r}
#| echo: false
#| eval: true
#| fig-align: center

lin_reg_fit %>%
  extract_fit_engine() %>%
  tidy() %>%
  ggplot() +
  geom_errorbarh(aes(xmin = estimate - 2*std.error, 
                     xmax = estimate + 2*std.error, 
                     y = term, 
                     color = term),
                 lwd = 1.25) +
  geom_point(aes(x = estimate, y = term, color = term), 
             size = 4) +
  geom_vline(xintercept = 0, linetype = "dashed", lwd = 2) + 
  labs(
    title = "Confidence Intervals for Model Coefficients",
    x = "Coefficient",
    y = ""
  ) +
  theme(legend.position = "None")
```

## Model Predictions

. . .

```{r}
std_err <- lin_reg_fit %>%
  glance() %>%
  pull(sigma)

x_plot <- tibble(
  x1 = seq(0, 10, length.out = 250),
  x2 = seq(0, 10, length.out = 250)
)

x_plot <- x_plot %>%
  bind_cols(
  lin_reg_fit %>%
    predict(x_plot)
  ) %>%
  bind_cols(
  lin_reg_fit %>%
    predict(x_plot,
            type = "conf_int",
            level = 0.95) %>%
    rename(.conf_lower = .pred_lower,
           .conf_upper = .pred_upper)) %>%
  bind_cols(
  lin_reg_fit %>%
    predict(x_plot,
            type = "pred_int",
            level = 0.95)
  ) %>%
  mutate(
    .aprx_lower = .pred - 2*std_err,
    .aprx_upper = .pred + 2*std_err
    )
  
ggplot() +
  geom_point(aes(x = x1_new, y = y1_new)) +
  geom_line(data = x_plot,
            aes(x = x1,
                y = .pred),
            color = "blue",
            lwd = 1.25) + 
  labs(
    title = "Model Predictions",
    x = "x",
    y = "y"
  )
```

. . .

They're all wrong!

## Confidence Intervals (Predictions)

. . .

The formula for confidence intervals on predictions is complex! 

. . .

$$\displaystyle{\left(\tt{point~estimate}\right)\pm t^*_{\text{df}}\cdot \left(\tt{RMSE}\right)\left(\sqrt{\frac{1}{n} + \frac{(x_{new} - \bar{x})^2}{\sum{\left(x - \bar{x}\right)^2}}}\right)}$$

. . . 

We'll use R to construct these intervals for us.

. . .


```{r}
#| fig-align: center
#| fig-height: 4
#| fig-width: 6

ggplot() +
  geom_ribbon(data = x_plot,
              aes(x = x1,
                  ymin = .conf_lower,
                  ymax = .conf_upper),
              fill = "grey",
              alpha = 0.75) +
  geom_line(data = x_plot,
            aes(x = x1,
                y = .pred),
            color = "blue",
            lwd = 1.25) + 
  geom_point(aes(x = x1_new, y = y1_new)) +
  labs(
    title = "Model with Confidence Intervals",
    x = "x1",
    y = "y"
  )
```

. . .

Are these wrong too?

## Confidence Intervals (Predictions)

The formula for confidence intervals on predictions is complex! 

$$\displaystyle{\left(\tt{point~estimate}\right)\pm t^*_{\text{df}}\cdot \left(\tt{RMSE}\right)\left(\sqrt{\frac{1}{n} + \frac{(x_{new} - \bar{x})^2}{\sum{\left(x - \bar{x}\right)^2}}}\right)}$$

We'll use R to construct these intervals for us.

```{r}
#| fig-align: center
#| fig.height: 5

ggplot() +
  geom_ribbon(data = x_plot,
              aes(x = x1,
                  ymin = .conf_lower,
                  ymax = .conf_upper),
              fill = "grey",
              alpha = 0.75) +
  geom_line(data = x_plot,
            aes(x = x1,
                y = .pred),
            color = "blue",
            lwd = 1.25) + 
  geom_point(aes(x = x1_new, y = y1_new)) +
  labs(
    title = "Model with Confidence Intervals",
    x = "x1",
    y = "y"
  )
```

Are these wrong too? No -- confidence intervals bound the *average response* over all observations having given input features.

## Prediction Intervals

. . .

So, can we build intervals which contain predictions on the level of an individual observation?

. . . 

Sure -- but there's added uncertainty in making those types of predictions

. . .

```{r}
ggplot() +
  geom_ribbon(data = x_plot,
              aes(x = x1,
                  ymin = .pred_lower,
                  ymax = .pred_upper),
              fill = "grey",
              alpha = 0.75) +
  geom_line(data = x_plot,
            aes(x = x1,
                y = .pred),
            color = "blue",
            lwd = 1.25) + 
  geom_point(aes(x = x1_new, y = y1_new)) +
  labs(
    title = "Model with Prediction Intervals",
    x = "x",
    y = "y"
  )
```

## Confidence and Prediction Intervals for Model Predictions

. . . 

```{r}
int_fills <- c("confidence" = "orange",
               "prediction" = "purple")

ggplot() +
  geom_ribbon(data = x_plot,
              aes(x = x1,
                  ymin = .pred_lower,
                  ymax = .pred_upper,
                  fill = "prediction"),
              alpha = 0.6) +
  geom_ribbon(data = x_plot,
              aes(x = x1,
                  ymin = .conf_lower,
                  ymax = .conf_upper,
                  fill = "confidence"),
              alpha = 0.8) +
  geom_line(data = x_plot,
            aes(x = x1,
                y = .pred),
            color = "blue",
            lwd = 1.25) + 
  geom_point(aes(x = x1_new, y = y1_new)) +
  scale_fill_manual(values = int_fills) +
  labs(
    title = "Model with Prediction and Confidence Intervals",
    fill = "Interval Type",
    x = "x",
    y = "y"
  )
```

## Summary

Below are the most common applications of statistical inference in regression modeling.

+ Hypothesis Tests

  + Does our model have any utility at all?
  + Are all of the included predictor terms useful?

+ Confidence Intervals

  + What is the plausible range for each parameter/coefficient? 
  
    + How do we interpret those ranges?
  + Can we make reliable predictions? 
  
    + Confidence Intervals for *average response*
    + Prediction Intervals for *individual response*
    
. . . 

We'll be utilizing all of these ideas throughout our course.

. . . 

We'll leverage R functionality to obtain intervals or to calculate test statistics and $p$-values though, since it is much faster than doing any of this by hand.

## Next Time... 

<center> 

<font size="120pt"><br/> Hypothesizing, Constructing, Assessing, and Interpreting Simple Linear Regression Models
</font>

</center>
    